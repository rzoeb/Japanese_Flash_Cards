{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese Language Flashcard Generation\n",
    "\n",
    "#### Overview\n",
    "This notebook automates the creation of Japanese language Anki flashcards from textbook images. It combines OCR technology with large language model processing to extract, verify, and format vocabulary into ready-to-import flashcards.\n",
    "\n",
    "#### Features\n",
    "- Extract Japanese text from textbook images using OCR API\n",
    "- Cross-reference extracted text with original images for accuracy\n",
    "- Generate structured CSV flashcards with proper formatting\n",
    "- Support for contextual vocabulary notes and usage examples\n",
    "\n",
    "#### Workflow\n",
    "1. **Image Upload**: Upload Japanese textbook page images  \n",
    "2. **Text Extraction**: Use OCR API to extract text from the images (Currently the LLMWhisperer API)  \n",
    "3. **LLM Processing**: Send both the extracted text and original image to an LLM (Currently the Gemini API is used)  \n",
    "4. **Flashcard Generation**: Generate structured CSV data using specialized prompts from `LLM_Prompts.py`  \n",
    "5. **Export**: Save the resulting flashcards in Anki-compatible CSV format  \n",
    "\n",
    "#### Flashcard Format\n",
    "The generated flashcards follow a specific CSV structure:\n",
    "- **Kanji column**: Contains the word in Kanji (or Hiragana/Katakana if no Kanji exists)  \n",
    "- **Furigana column**: Contains the phonetic reading of the word in Hiragana  \n",
    "- **English_Translation_and_Notes column**: Contains both the English translation and any usage or contextual notes  \n",
    "\n",
    "Example output:\n",
    "```\n",
    "\"迷う [道に～]\",\"まよう [みちに～]\",\"lose one's way (e.g., get lost on the road)\"  \n",
    "\"先輩\",\"せんぱい\",\"senior (student, colleague, etc.)\"  \n",
    "```\n",
    "\n",
    "#### Benefits\n",
    "- **Accuracy**: Cross-references OCR text with the original image to fix errors  \n",
    "- **Context-Aware**: Preserves usage examples and contextual information  \n",
    "- **Time-Saving**: Automates the tedious process of manual flashcard creation  \n",
    "- **Customizable**: Prompts can be adjusted for different textbook formats  \n",
    "\n",
    "#### Applications\n",
    "- Creating comprehensive JLPT study materials  \n",
    "- Building personal vocabulary decks from textbooks  \n",
    "- Supplementing classroom learning with digital flashcards  \n",
    "- Archiving vocabulary from various Japanese learning resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the example images (which are used with the prompts in 'LLM_Prompts.py') as base64 strings in a JSON file\n",
    "# This only has to be done once to generate the JSON file (or any time the example images are changed)\n",
    "# Importing the required libraries\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Defining variables\n",
    "image_path_example_1 = r\"C:\\Users\\Rounak\\OneDrive\\Documents\\Japanese Study\\Flashcards - Textbook Photos and Text Files\\MNN Beginner 1 & 2 - Useful Words & Information\\Chapter 12.jpg\"\n",
    "image_path_example_2 = r\"C:\\Users\\Rounak\\OneDrive\\Documents\\Japanese Study\\Flashcards - Textbook Photos and Text Files\\MNN Intermediate 1\\Chatpter 1\\01page_1.jpg\"\n",
    "\n",
    "# Function to encode an image to base64\n",
    "# image_path: Path to the image file\n",
    "# Returns: Base64 encoded string of the image\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8') # Decode to string for text storage\n",
    "            return encoded_string\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at: {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image {image_path} to base64: {e}\")\n",
    "        return None\n",
    "\n",
    "# Encode the example images to base64 strings\n",
    "base64_string_example_1 = image_to_base64(image_path_example_1)\n",
    "base64_string_example_2 = image_to_base64(image_path_example_2)\n",
    "\n",
    "# Check if encoding was successful for both images\n",
    "if base64_string_example_1 and base64_string_example_2: # Only proceed if encoding was successful for both\n",
    "    # Create a dictionary to store the base64 strings\n",
    "    base64_image_data = {\n",
    "        \"flashcard_image_example_1\": base64_string_example_1,\n",
    "        \"flashcard_image_example_2\": base64_string_example_2\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    json_filepath = \"base64_example_images.json\"\n",
    "    try:\n",
    "        with open(json_filepath, \"w\") as json_file:\n",
    "            json.dump(base64_image_data, json_file, indent=4) # indent=4 for pretty formatting (optional)\n",
    "        print(f\"Base64 image strings written to: {json_filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to JSON file {json_filepath}: {e}\")\n",
    "else:\n",
    "    print(\"Error: Could not encode one or more images to base64. JSON file not created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading base64 images from a JSON file into a PIL Image object\n",
    "# Importing the required libraries\n",
    "import json\n",
    "import base64\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to load base64 images from a JSON file\n",
    "# filepath: Path to the JSON file containing base64 image strings\n",
    "# Returns: Dictionary with image names as keys and PIL Image objects as values\n",
    "def load_base64_images_from_json(filepath=\"base64_example_images.json\"):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            base64_images = json.load(f)\n",
    "        return base64_images\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {filepath}\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in {filepath}\")\n",
    "        return {}\n",
    "\n",
    "# Function to load a base64 image string into a PIL Image object\n",
    "# base64_string: Base64 encoded image string\n",
    "# Returns: PIL Image object\n",
    "def load_image_from_base64(base64_string):\n",
    "    try:\n",
    "        image_bytes = base64.b64decode(base64_string)\n",
    "        image = PIL.Image.open(BytesIO(image_bytes))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from base64: {e}\")\n",
    "        return None\n",
    "\n",
    "base64_example_image_dict = load_base64_images_from_json()\n",
    "if base64_example_image_dict:\n",
    "    image_example_1 = load_image_from_base64(base64_example_image_dict[\"flashcard_image_example_1\"])\n",
    "    image_example_2 = load_image_from_base64(base64_example_image_dict[\"flashcard_image_example_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting text from an image using the LLMWhisperer API\n",
    "# The LLMWhisperer API is a powerful OCR API that can be used to extract text from images.\n",
    "# Importing the required libraries\n",
    "from unstract.llmwhisperer import LLMWhispererClientV2\n",
    "import os\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Defining variables\n",
    "load_dotenv()\n",
    "unstract_api_url = os.getenv(\"LLMWHISPERER_BASE_URL_V2\")\n",
    "unstract_api_key = os.getenv(\"LLMWHISPERER_API_KEY\")\n",
    "image_actual_path = r\"C:\\Users\\Rounak\\OneDrive\\Documents\\Japanese Study\\Flashcards - Textbook Photos and Text Files\\MNN Intermediate 1\\Chatpter 1\\01page_1.jpg\"\n",
    "\n",
    "# Check if image_actual_path exists\n",
    "if not os.path.exists(image_actual_path):\n",
    "    print(\"Image path does not exist\")\n",
    "    exit()\n",
    "\n",
    "# Converting the image into a byte stream (IO[bytes] object) for use with the LLMWhisperer API\n",
    "image_bytes = BytesIO(open(image_actual_path, \"rb\").read())\n",
    "\n",
    "# Extract text from the image using LLMWhisperer\n",
    "client = LLMWhispererClientV2(base_url=unstract_api_url, api_key=unstract_api_key, logging_level=\"ERROR\")  # Change the logging level to \"ERROR\" for production\n",
    "result = client.whisper(stream=image_bytes, wait_for_completion=True)\n",
    "image_actual_extracted_text = result[\"extraction\"][\"result_text\"]\n",
    "print(image_actual_extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"検査する\",\"けんさする\",\"examine, inspect\"\n",
      "\"明日\",\"あす\",\"tomorrow\"\n",
      "\"能力\",\"のうりょく\",\"capability\"\n",
      "\"バザー\",\"バザー\",\"bazaar\"\n",
      "\"マスク\",\"マスク\",\"nose and mouth mask\"\n",
      "\"スーツケース\",\"スーツケース\",\"suitcase\"\n",
      "\"目が覚める\",\"めがさめる\",\"wake up, realize\"\n",
      "\"朝礼\",\"ちょうれい\",\"morning meeting\"\n",
      "\"校歌\",\"こうか\",\"school song\"\n",
      "\"敬語\",\"けいご\",\"honorific language\"\n",
      "\"感想文\",\"かんそうぶん\",\"review (e.g., of a book one has read)\"\n",
      "\"運動場\",\"うんどうじょう\",\"sports ground\"\n",
      "\"いたずら\",\"いたずら\",\"prank\"\n",
      "\"美しい\",\"うつくしい\",\"beautiful\"\n",
      "\"世紀\",\"せいき\",\"century\"\n",
      "\"平和 [な]\",\"へいわ [な]\",\"peaceful\"\n",
      "\"人々\",\"ひとびと\",\"people\"\n",
      "\"願う\",\"ねがう\",\"desire, wish for, hope for\"\n",
      "\"文\",\"ぶん\",\"sentence, style\"\n",
      "\"書き換える\",\"かきかえる\",\"rewrite\"\n",
      "\"合わせる\",\"あわせる\",\"combine\"\n",
      "\"もともと\",\"もともと\",\"originally\"\n",
      "\"若者\",\"わかもの\",\"young person\"\n",
      "\"~湖\",\"~こ\",\"lake~\"\n",
      "\"深い\",\"ふかい\",\"deep\"\n",
      "\"さまざま [な]\",\"さまざま [な]\",\"various\"\n",
      "\"苦しい [生活が～]\",\"くるしい [せいかつが～]\",\"hard\"\n",
      "\"性格\",\"せいかく\",\"character\"\n",
      "\"人気者\",\"にんきもの\",\"popular person\"\n"
     ]
    }
   ],
   "source": [
    "# Generating the flashcards based on the supplied image (specified by 'image_path') and the extracted text (specified by 'image_actual_extracted_text')\n",
    "# Importing the required libraries\n",
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "import json\n",
    "from unstract.llmwhisperer import LLMWhispererClientV2\n",
    "import os\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "\n",
    "# Importing all variables from LLM_Prompts.py\n",
    "from LLM_Prompts import *\n",
    "\n",
    "# Defining Functions\n",
    "# Function to load base64 images from a JSON file\n",
    "# filepath: Path to the JSON file containing base64 image strings\n",
    "# Returns: Dictionary with image names as keys and PIL Image objects as values\n",
    "def load_base64_images_from_json(filepath=\"base64_example_images.json\"):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            base64_images = json.load(f)\n",
    "        return base64_images\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {filepath}\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in {filepath}\")\n",
    "        return {}\n",
    "\n",
    "# Function to load a base64 image string into a PIL Image object\n",
    "# base64_string: Base64 encoded image string\n",
    "# Returns: PIL Image object\n",
    "def load_image_from_base64(base64_string):\n",
    "    try:\n",
    "        image_bytes = base64.b64decode(base64_string)\n",
    "        image = PIL.Image.open(BytesIO(image_bytes))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from base64: {e}\")\n",
    "        return None\n",
    "\n",
    "# Defining the variables\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GOOGLE_GEMINI_API_KEY\")\n",
    "unstract_api_url = os.getenv(\"LLMWHISPERER_BASE_URL_V2\")\n",
    "unstract_api_key = os.getenv(\"LLMWHISPERER_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "# model = genai.GenerativeModel(\"gemini-2.0-flash-thinking-exp-01-21\")\n",
    "\n",
    "image_actual_path = r\"C:\\Users\\Rounak\\OneDrive\\Documents\\Japanese Study\\Flashcards - Textbook Photos and Text Files\\MNN Intermediate 1\\Chatpter 4\\01page_1.jpg\" # User uploaded image for Streamlit\n",
    "\n",
    "# Check if image paths exists\n",
    "if not os.path.exists(image_actual_path):\n",
    "    print(\"Image path does not exist\")\n",
    "    exit()\n",
    "\n",
    "image_actual = PIL.Image.open(image_actual_path)\n",
    "\n",
    "# Determining if the supplied image is suitable for flashcard generation\n",
    "# Creating the content object for the suitability assessment (that will be passed to the Gemini API)\n",
    "content_suitability = [\n",
    "    suitability_system_prompt,\n",
    "    image_actual,\n",
    "    suitability_user_prompt,\n",
    "]\n",
    "\n",
    "# Retrieving the suitability assessment for the image from the API\n",
    "try:\n",
    "    response_suitability = model.generate_content(content_suitability)\n",
    "    response_suitability.resolve() # This will raise an exception if there is an error in the response.\n",
    "\n",
    "    # Extracting the suitability assessment from the API response and loading it as a JSON object\n",
    "    json_string = response_suitability.text.replace(\"```json\", \"\").replace(\"```\", \"\") # Removing the code block markdown\n",
    "    json_output = json.loads(json_string)\n",
    "\n",
    "    is_suitable = json_output.get(\"is_suitable\")\n",
    "    reason = json_output.get(\"reason\")\n",
    "\n",
    "    if is_suitable != \"Yes\":\n",
    "        print(\"Image is NOT suitable for flashcard generation.\")\n",
    "        print(f\"Reason: {reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating suitability assessment: {e}\")\n",
    "    if 'response_suitability' in locals(): # The API response is only printed if it exists\n",
    "        print(f\"API Response: {response_suitability.prompt_feedback}\")\n",
    "\n",
    "# Generating the flashcards if the image is marked as suitable for flashcard generation\n",
    "if is_suitable == \"Yes\":\n",
    "    # Loading base64 images from a JSON file into a PIL Image object\n",
    "    base64_example_image_dict = load_base64_images_from_json()\n",
    "    if base64_example_image_dict:\n",
    "        image_example_1 = load_image_from_base64(base64_example_image_dict[\"flashcard_image_example_1\"])\n",
    "        image_example_2 = load_image_from_base64(base64_example_image_dict[\"flashcard_image_example_2\"])\n",
    "\n",
    "    # Extracting text from the image using the LLMWhisperer API\n",
    "    # The LLMWhisperer API is a powerful OCR API that can be used to extract text from images.\n",
    "    # Converting the image into a byte stream (IO[bytes] object) for use with the LLMWhisperer API\n",
    "    image_bytes = BytesIO(open(image_actual_path, \"rb\").read())\n",
    "\n",
    "    # Extract text from the image using LLMWhisperer\n",
    "    client = LLMWhispererClientV2(base_url=unstract_api_url, api_key=unstract_api_key, logging_level=\"ERROR\")  # Change the logging level to \"ERROR\" for production\n",
    "    result = client.whisper(stream=image_bytes, wait_for_completion=True)\n",
    "    image_actual_extracted_text = result[\"extraction\"][\"result_text\"]\n",
    "\n",
    "    # Creating the content object for the flashcard generation (that will be passed to the Gemini API)\n",
    "    content_flashcards = [\n",
    "        flashcard_system_prompt,\n",
    "\n",
    "        image_example_1,\n",
    "        flashcard_user_prompt_example_1,\n",
    "        flashcard_answer_example_1,\n",
    "\n",
    "        image_example_2,\n",
    "        flashcard_user_prompt_example_2,\n",
    "        flashcard_answer_example_2,\n",
    "\n",
    "        image_actual,\n",
    "        flashcard_user_prompt_actual.format(extracted_text = image_actual_extracted_text),\n",
    "    ]\n",
    "\n",
    "    # Retrieving the flashcards from the API\n",
    "    try:\n",
    "        response_flashcards = model.generate_content(content_flashcards)\n",
    "        response_flashcards.resolve() # This will raise an exception if there is an error in the response.\n",
    "\n",
    "        # Extracting the flashcards from the API response\n",
    "        flashcards = response_flashcards.text.replace(\"```html\", \"\").replace(\"```csv\", \"\").replace(\"```\", \"\") # Removing the code block markdown\n",
    "        print(flashcards)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating flashcards: {e}\")\n",
    "        if 'response_flashcards' in locals(): # The API response is only printed if it exists\n",
    "            print(f\"API Response: {response_flashcards.prompt_feedback}\")\n",
    "    \n",
    "# Saving the flashcards to a .txt file\n",
    "with open(\"generated_flashcards.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(flashcards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
